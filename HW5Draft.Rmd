---
title: "HW5: Count Regression"
author: "Tora Mullings, Deepa Sharma, Daniel Sullivan, Deepika Dilip, Bikram Barua, Newman Okereafor"
date: '2022-11-26'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```

# Background
Given a set of metrics describing the quality of different wines, can we predict the number of sales of each wine? Since the target is a count response variable, we will build models appropriate for count regression. After evaluating our set of models, we will select the best one and predict the number of sales in a wine data set the model has not yet seen.

# Data Exploration

```{r, include=FALSE}
library(corrplot)
library(reshape2)
library(MASS)
library(tidyverse)
library(ggplot2)
library(ggfortify)
library(ggthemes)
library(knitr)
library(broom)
library(caret)
library(leaps)
library(MASS)
library(magrittr)
library(betareg)
library(pscl)
library(gtsummary)
library(nnet)
library(arm)
library(AER)
library(kableExtra)
```


```{r, include=FALSE}
wine.train <- read.csv('https://raw.githubusercontent.com/djunga/DATA621HW5/main/wine-training-data.csv')
wine.eval <- read.csv('https://raw.githubusercontent.com/djunga/DATA621HW5/main/wine-evaluation-data.csv')
```

### Statistical Summary of Variables
```{r, echo=FALSE}
summary(wine.train)
```

### Description of Variables
```{r, echo=FALSE}
str(wine.train)
```



* There are 12,795 observations and 16 columns.
* Of these columns, 14 are predictors.
* Of the remaining 2, there is an index column with invalid characters, so it will need to be renamed. The column with the response variable is named `TARGET`.
* `TARGET`, the response variable, is the number of sample cases of wine that were purchased by wine distribution companies after sampling a wine.
* Aside from `STARS` and `LabelAppeal`, the predictors are mostly chemical metrics of the wines.
* Values in `STARS` are ratings given to the wines by experts whereas values in `LabelAppeal` are marketing scores indicate the level of visual appeal of the wine label to customers. Note that`LabelAppeal` is not a score given by customers themselves, but by marketing tools that have used other sources to make assumptions.
* The target has a small range, 0-8. This indicates that fewer than 10 of each wine has been sold.

## Missing values

```{r}
(colSums(is.na(wine.train)) / nrow(wine.train)) * 100
```

Over 25% of the wines don't have a value for `STARS`, meaning they have not been rated by experts. What is the relationship between lack of a rating and number of sales? 

```{r}
missing_val <- data.frame(num_missing=colSums(is.na(wine.train)))
ggplot(wine.train, aes(STARS, TARGET)) + geom_jitter(width=0.5, height=0.5)
```


### Correlation Plot

```{r}
colnames(wine.train)[1] <- "INDEX"
corrplot::corrplot(cor(wine.train, use = "complete.obs"), tl.col="black", tl.cex=0.6, order='AOE')
```


* There is a positive correlation between `STARS`, `LabelAppeal`, and `TARGET`. This makes sense because the better a wine label appears, the more likely a customer will buy the wine. And if an expert rates a wine highly, it is indicative that other people will like it is as well and decide to buy it.
* There is a slight negative correlation between `AcidIndex` and `TARGET`, and it is interesting that this does not appear to be the case for `pH` and `TARGET`. Since pH is also a metric for acidity, we might have expected a relationship to exist.

## Distribution of Variables

### Histograms of Distributions of Predictors & Target

```{r, warning=FALSE, message=FALSE}
mlt.train = wine.train 
mlt.train = melt(mlt.train, id.vars = "INDEX")

ggplot(aes(value), data = mlt.train) + geom_histogram(stat = "bin", fill = "navyblue") + facet_wrap(~variable, scales = "free") + labs(title = "Distributions of Continuous Variables", x = "Variable", y = "Count") 
```

Note that `TARGET` contains many 0 values. This means that many of the wines have 0 sales. 
```{r, include=FALSE}
sum(wine.train %>% select("TARGET") == 0) / nrow(wine.train)
```
Upon further inspection, we determine that 21% of the wines have 0 sales. We will explore how much the frequency of zeroes in `TARGET` affects our models later.


### Scatterplots of Target vs Predictors

```{r, fig.height= 10, fig.width = 14}
mlt.train <- melt(wine.train, id.vars = c("INDEX", "TARGET"))
ggplot(aes(value, TARGET), data = mlt.train) + geom_point() + facet_wrap(~variable, scales = "free") + labs(title = "Distributions of Continuous Variables", x = "Variable", y = "TARGET") 
```

For the `AcidIndex`, `STARS`, and `LabelAppeal` predictors, due to the small range of both them and the target variable, it may be easier to see their relationships if the data is jittered. Also, how large is the difference between `pH` and `AcidIndex`?

```{r, warning=FALSE, fig.width = 7}
# ggplot(wine.train, aes(AcidIndex, TARGET)) +
#   geom_jitter(width = 0.5, height = 0.5)
mlt.train <- melt(select(wine.train, "pH", "AcidIndex", "LabelAppeal", "STARS", "TARGET"), id.vars = c("TARGET"))
ggplot(aes(value, TARGET), data = mlt.train) + geom_jitter(width = 0.5, height = 0.5) + facet_wrap(~variable, scales = "free") + labs(title = "Distributions of Continuous Variables Subset, Jittered", x = "Variable", y = "TARGET") 
```


* There is a clear positive relationship between `LabelAppeal`, `STARS`, and `TARGET`.
* The `AcidIndex` plot reveals that most of the wines have a lower total acidity, between 5 and 10.
* The pH of most of the wine samples are also low, between 2 and 5.

# Build Models

### Model #1: Full Multiple Linear Regression
```{r}
mod1 <- lm(TARGET ~ ., data=select(wine.train, -"INDEX"))
summary(mod1)
```
44% of the variability observed in the number of sales is explained by the model.


### Model #2: Multiple regression with Manually Selected Features
We choose the highly significant variables as outputted by the previous model:

* VolatileAcidity
* Sulphates
* Alcohol
* LabelAppeal
* AcidIndex
* STARS
```{r}
mod2 <- lm(TARGET ~ VolatileAcidity + Sulphates + Alcohol + LabelAppeal + AcidIndex + STARS, data=wine.train)
summary(mod2)
```

The Adjusted $R^{2}$ is hardly better, as seen by the output below:

```{r}
mod2 %>%glance()
```

## Evaluation of the Multiple Linear Regression Models

Multicollinearity is when independent variables are correlated. Variance Inflation (VIF) is a metric that can be used to determine multicollinearity between variables in a model. A score over 5 is considered severe, and the variable would not be as statistically significant. If there is a problem with multicollinearity, one solution is to carefully trim the model by removing some of the offending variables.


### Variance Inflation and Diagnostic Plots for Model 1
```{r}
car::vif(mod1)
```

```{r}
autoplot(mod1)
```


### Variance Inflation and Diagnostic Plots for Model 2
```{r}
car::vif(mod2)
```

```{r}
autoplot(mod2)
```
In each model, the VIF scores are very close to 1, which is good. Still, there is overall evidence that a multiple linear regression is not the right fit for this data.

## Model #3: Full Poisson

```{r}
Poisson_Model1<- glm(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
              Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
              pH + Sulphates + Alcohol + 
              as.factor(LabelAppeal) +
              as.factor(AcidIndex) +
              as.factor(STARS),
              data=wine.train, 
              family=poisson
            )
summary(Poisson_Model1)

```
### Test Dispersion on Model 3

```{r}
#Test Dispersion from AER package
dispersiontest(Poisson_Model1, trafo = 1)
```
Since the p value is 1, meaning this is not Over-dispersion Which is good.


## Model #4: Poisson With Selected Predictors
We choose the highly significant variables as outputted by Model 3:

* VolatileAcidity
* Chlorides
* FreeSulfurDioxide
* TotalSulfurDioxide
* Sulphates
* Alcohol
* LabelAppeal
* AcidIndex
* STARS


```{r}
Poisson_Model2 <- glm(TARGET ~ VolatileAcidity + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Sulphates +Alcohol + 
              as.factor(LabelAppeal) + 
              as.factor(AcidIndex) + 
              as.factor(STARS),
              data=wine.train, 
              family=poisson
             )
summary(Poisson_Model2)
```

The deviance residuals increases than before with increase degrees of freedom.
Furthermore, the AIC score increased significantly from 23087 to 24948. So we can say Poisson Model 1 is better fit than Model2.
 
Since the residual deviance is smaller than the degrees of freedom, then our data is under-dispersion.


### Test Dispersion on Model 4

```{r}
dispersiontest(Poisson_Model2, trafo = 1)
```
Since the p value is exactly 1, meaning this is not Over-dispersion Which is good.


## Model #5: Full Negative Binomial

```{r}
Negative_Bin_Model1 <- glm.nb(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
                Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
                pH + Sulphates + Alcohol + 
                as.factor(LabelAppeal) +
                as.factor(AcidIndex) +
                as.factor(STARS),
              data=wine.train)
summary(Negative_Bin_Model1)
```

## Model #6: Negative Binomial with Selected Variables
We choose the highly significant variables as outputted by Model 5:

* VolatileAcidity
* Chlorides
* FreeSulfurDioxide
* TotalSulfurDioxide
* Sulphates
* Alcohol
* LabelAppeal
* AcidIndex
* STARS


```{r}
Negative_Bin_Model2 <- glm.nb(TARGET~ VolatileAcidity + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Sulphates 
              + 
              Alcohol + 
              as.factor(LabelAppeal) + 
              as.factor(AcidIndex) + 
              as.factor(STARS),
              data=wine.train)
summary(Negative_Bin_Model2)

```
Looking into the AIC value, we can say that Model 5 is better than Model 6.


## Model #7: Full Quasi-Poisson

Since the data set indicates under-dispersion it is a good idea to fit a Quasi-Poisson regression model and check whether we see any difference in the standard error estimation for the model regression coefficients.


```{r}
Quasi_Poisson_Model1<- glm(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
              Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
              pH + Sulphates + Alcohol + 
              as.factor(LabelAppeal) +
              as.factor(AcidIndex) +
              as.factor(STARS),
              data=wine.train, 
              family=quasipoisson
            )
summary(Quasi_Poisson_Model1)

 
```

## Model #8: Quasi-Poisson with Selected Variables

```{r}
Quasi_Poisson_Model2 <- glm(TARGET ~ VolatileAcidity + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Sulphates +Alcohol + 
              as.factor(LabelAppeal) + 
              as.factor(AcidIndex) + 
              as.factor(STARS),
              data=wine.train, 
              family=quasipoisson
             )
summary(Quasi_Poisson_Model2)

```

## Comparison Negative Binomial, Poisson Regression, and Quasi Poisson Regression models: Coefficients and Std Errors


```{r}
pois.coef = coef(Poisson_Model2)
negbinom.coef = coef(Negative_Bin_Model2)
pois.stderr = se.coef(Poisson_Model2)
negbinom.stderr = summary(Negative_Bin_Model2)$coefficients[, 2]
pois.quasi.coef = coef(Quasi_Poisson_Model2)
pois.quasi.stderr = se.coef(Quasi_Poisson_Model2)
df.analysis = cbind(pois.coef,   negbinom.coef,   pois.quasi.coef, 
                    pois.stderr, negbinom.stderr, pois.quasi.stderr)
head(df.analysis,10) %>% kable() %>% kable_styling(c("striped", "bordered"))


```

* From the above table we can see that the model coefficients and standard errors for Poisson and Negative Binomial regression models are the same up to 4 decimal places.
This can be due to the fact that under-dispersion in the dataset is not severe enough to impact the accuracy of the Poisson regression model.

* The model coefficients for Poisson Regression and Quasi-Poisson Regression models are same, but the estimates for the standard errors are different. This is expected since the data set has under-dispersion.

* Standard error estimations for regression coefficients of the Poisson regression model will not be accurate. We need to rely on standard error estimates from the Quasi-Poisson regression model, which is better suited for data sets exhibiting under-dispersion or over-dispersion.

* If we need to use these coefficients for inference, it is better to rely on standard error estimates from the Quasi Poisson regression model to calculate the confidence intervals, rather than from the normal Poisson regression model, for better accuracy of inference.


## Consider Zero-Inflation

Previously, we determined that 21% of the wines have 0 sales. Also, over 25% of the wines have not been rated by an expert, indicated by `STARS`. Is there a relationship? Of the predictors with missing values, we can visualize the relationship between them and the number of sales. Recall that the number of sales amongst all the wines ranged from 0-8.


```{r}
predictor_names <- colnames(wine.train %>% select(c("ResidualSugar","Chlorides","FreeSulfurDioxide",
                                                     "TotalSulfurDioxide","pH","Sulphates","Alcohol","STARS")))

missing_val <- data.frame(INDEX=NA, Variable=NA, value=NA)
colnames(missing_val) <- c("INDEX", "Variable", "value")

for (name in predictor_names) {
  
  #new_missing <- data.frame(cbind(rep(name,5), wine.train %>% filter(is.na(wine.train[name])) %>% count(STARS)))
  missing_stars_count <- wine.train %>% filter(is.na(wine.train[name])) %>% count(TARGET)
  new_missing <- data.frame(cbind(rep(name,nrow(missing_stars_count)), missing_stars_count))
  colnames(new_missing) <- c("INDEX", "Variable", "value")
  
  missing_val <-  rbind(missing_val, new_missing)
}

# drop first row of NAs
missing_val <- missing_val %>%
  filter(!row_number() %in% c(1))

ggplot(data=missing_val) + geom_bar(mapping=aes(x=Variable, y=value), stat="identity") + facet_wrap(~INDEX, scales = "fixed") + labs(title = "Missing Predictors vs Sales", x = "Num sales", y = "Count")  
```

The bar at 0 in the `STARS` plot stands out as the largest. It indicates that about 2000 wines without experts' ratings had no sales. It is much more than any other predictor. There is a clear relationship between the number of wines that don't have an expert's rating and the number of sales. When there is no rating, no wine is sold. 

Since there is a large number of 0 sales that is likely related to the `STARS` predictor, we can build a zero-inflated negative binomial model. A zero-inflated model assumes that a zero outcome is due to two different processes. For this model, it assumes that if there is no expert rating, then a zero is produced. If there is an expert rating, then the count portion of the model will be used instead. Since the other portion has only 2 outcomes, we can use the negative binomial model. In other words, the overall model is a combination of two models. 

Here, the model will take the `STARS` predictor for the negative binomial portion, and all of the predictors in the count portion.

## Model #9: Full Zero-Inflated Negative Binomial

```{r}
ZInflatedModel <- zeroinfl(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + 
    ResidualSugar + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + 
    Density + pH + Sulphates + Alcohol + as.factor(LabelAppeal) + 
    as.factor(AcidIndex)  | STARS,
  data = wine.train, dist = "negbin")
summary(ZInflatedModel)
```


The `STARS` predictor is statistically significant, as well as `VolatileAcidity`, `Alcohol`, and `LabelAppeal`. A simpler model with these predictors can be built.

## Model #10: Zero-Inflated Negative Binomial with Selected Variables

```{r}
ZInflatedModel2 <- zeroinfl(TARGET ~ VolatileAcidity + 
    Alcohol + as.factor(LabelAppeal)  | STARS,
  data = wine.train, dist = "negbin")
summary(ZInflatedModel2)
```

One takeaway from the model output is the log odds of the number of sales, `TARGET`, being an excessive zero would decrease by 3.7 for every additional unit increase in the expert rating. In other words, the higher the expert rating, the more likely that the wine had at least one sale.



## Predictions

Does the evaluation set have characteristics to the training set?

```{r}
(colSums(is.na(wine.eval)) / nrow(wine.eval)) * 100
```


Similar to the training set, over 25% of the wines don't have a value for `STARS`. Now that we have revealed the relationship between the absence of an expert's rating and 0 sales, we decide to use the simpler zero-inflated negative binomial model.


```{r}
colnames(wine.eval)[1] <- "INDEX"
```

```{r}
wine.eval$TARGET <- round(predict(ZInflatedModel2, wine.eval %>% select(-c("INDEX", "TARGET")), type="response"))
```

We notice that there are many NAs for `TARGET`. How many are owed to NAs in `STARS`? The number of observations where both `STARS` is NA and `TARGET` is NA is 3,335. The number of observations where `STARS` is NA and `TARGET` is **not** NA is 0.

```{r, include=FALSE}
wine.eval %>% filter(is.na(STARS) && is.na(TARGET)) %>% count()
```

```{r, include=FALSE}
wine.eval %>% filter(is.na(STARS) && !is.na(TARGET)) %>% count()
```

Every NA in `TARGET` is an effect of an NA in `STARS`. As seen in the training set, the number of sales for wines without an expert rating is overwhelmingly zero. We can add these zeroes in place of the NAs in `TARGET`. Finally, make predictions on the evaluation set.

```{r}
wine.eval[is.na(wine.eval$TARGET), 'TARGET'] <- 0
```


```{r, include=FALSE}
#write_csv(wine.eval,"HW5_predictions.csv")
```


### Distribution of Predictions of Sales
```{r}
ggplot(data=wine.eval) + geom_histogram(mapping=aes(x=TARGET))
```

Although the evaluation set is about 25% of the size of the training set, the distribution of `TARGET` appears similar. We also note that the range of `TARGET` is smaller for the evaluation set, 0-6. Also, there are only 2 wines that were predicted to sell only once.


# Conclusion

Based on diagnostic plots and visualizations of relationships between variables, were able to determine that there is a strong connection between lack of an expert's rating and whether or not the wine was sold. In order to maximize sales, we propose prioritizing having the wines rated. 



